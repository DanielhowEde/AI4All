Sprint 3: Coordinator Protocol + Benchmark (Weeks 5-6) Goal: Connect to coordinator, receive tasks, execute, return results. First-run benchmark. Task Effort Description 3.1 WebSocket client 8h tokio-tungstenite, auto-reconnect 3.2 Protocol messages 6h Registration, heartbeat, task assignment 3.3 Message serialization 4h JSON with versioning 3.4 Connection state machine 8h Connecting → Registered → Working → Disconnected 3.5 Task execution loop 8h Receive → Execute → Submit result 3.6 Health reporting 4h Periodic status to coordinator 3.7 Benchmark system 12h CPU baseline, score calculation, storage 3.8 First-run experience 6h Auto-benchmark on first launch 3.9 Integration tests 8h Mock coordinator, full flow Sprint 3 Total: ~64 hours Protocol Messages (Task 3.2): // src/protocol/messages.rs #[derive(Debug, Serialize, Deserialize)] #[serde(tag = "type")] pub enum ClientMessage { /// Register with coordinator Register { worker_id: String, capabilities: WorkerCapabilities, benchmark_score: Option<f64>, }, /// Periodic heartbeat Heartbeat { worker_id: String, status: WorkerStatus, resource_usage: ResourceUsage, }, /// Request work assignment RequestWork { worker_id: String, }, /// Submit completed work SubmitResult { worker_id: String, block_id: String, result: TaskResult, }, } #[derive(Debug, Serialize, Deserialize)] #[serde(tag = "type")] pub enum ServerMessage { /// Registration acknowledged Registered { session_id: String, heartbeat_interval_ms: u64, }, /// Work assignment Assignment { block_id: String, task_type: TaskType, input: serde_json::Value, deadline: DateTime<Utc>, model_id: String, }, /// No work available NoWork { retry_after_ms: u64, }, /// Result acknowledged ResultAck { block_id: String, accepted: bool, error: Option<String>, }, /// Error from server Error { code: String, message: String, }, } #[derive(Debug, Serialize, Deserialize)] pub struct WorkerCapabilities { pub backend: String, // "cpu", "cuda", "rocm" pub supported_tasks: Vec<TaskType>, pub supports_training: bool, pub vram_mb: Option<u64>, pub memory_mb: u64, pub compute_score: f64, // From benchmark } #[derive(Debug, Serialize, Deserialize)] pub enum WorkerStatus { Idle, Working { block_id: String, progress: f32 }, Benchmarking, Error { message: String }, } Connection State Machine (Task 3.4): // src/protocol/connection.rs pub enum ConnectionState { Disconnected, Connecting, Connected { session_id: String }, Registered { session_id: String }, Working { session_id: String, block_id: String }, } pub struct CoordinatorConnection { state: ConnectionState, config: ConnectionConfig, ws: Option<WebSocketStream>, reconnect_attempts: u32, } impl CoordinatorConnection { pub async fn connect(&mut self) -> Result<()> { self.state = ConnectionState::Connecting; loop { match self.try_connect().await { Ok(ws) => { self.ws = Some(ws); self.state = ConnectionState::Connected { session_id: String::new() }; self.reconnect_attempts = 0; return Ok(()); } Err(e) => { self.reconnect_attempts += 1; if self.reconnect_attempts > self.config.max_reconnect_attempts { return Err(Error::MaxReconnectsExceeded); } let delay = self.config.reconnect_interval_ms * 2u64.pow(self.reconnect_attempts.min(5)); tracing::warn!( "Connection failed (attempt {}), retrying in {}ms: {}", self.reconnect_attempts, delay, e ); tokio::time::sleep(Duration::from_millis(delay)).await; } } } } pub async fn register(&mut self, capabilities: WorkerCapabilities) -> Result<()> { let msg = ClientMessage::Register { worker_id: self.config.worker_id.clone(), capabilities, benchmark_score: None, // Set after benchmark }; self.send(&msg).await?; match self.receive().await? { ServerMessage::Registered { session_id, heartbeat_interval_ms } => { self.state = ConnectionState::Registered { session_id }; self.start_heartbeat(heartbeat_interval_ms); Ok(()) } ServerMessage::Error { code, message } => { Err(Error::RegistrationFailed { code, message }) } _ => Err(Error::UnexpectedMessage), } } } Benchmark System (Task 3.7): // src/benchmark/mod.rs pub struct BenchmarkSuite { results_path: PathBuf, } #[derive(Debug, Serialize, Deserialize)] pub struct BenchmarkResult { pub timestamp: DateTime<Utc>, pub backend: String, pub model: String, pub scores: BenchmarkScores, pub hardware: HardwareInfo, } #[derive(Debug, Serialize, Deserialize)] pub struct BenchmarkScores { /// Tokens per second for text generation pub tokens_per_second: f64, /// Time to first token (ms) pub time_to_first_token_ms: f64, /// Memory efficiency (tokens / MB used) pub memory_efficiency: f64, /// Composite score (weighted average) pub composite: f64, } impl BenchmarkSuite { pub async fn run(&self, backend: &dyn InferenceBackend) -> Result<BenchmarkResult> { tracing::info!("Starting benchmark for backend: {}", backend.name()); // Standard benchmark prompts let prompts = [ ("short", "Hello, world!"), ("medium", "Explain quantum computing in simple terms."), ("long", include_str!("../fixtures/long_prompt.txt")), ]; let mut total_tokens = 0u64; let mut total_time_ms = 0u64; let mut first_token_times = Vec::new(); for (name, prompt) in prompts { tracing::info!("Running benchmark: {}", name); let start = Instant::now(); let mut first_token_time = None; let input = TextCompletionInput { prompt: prompt.to_string(), max_tokens: 100, temperature: 0.0, // Deterministic for benchmark ..Default::default() }; let output = backend.text_completion(input).await?; let elapsed = start.elapsed(); total_tokens += output.usage.completion_tokens as u64; total_time_ms += elapsed.as_millis() as u64; // Approximate first token time (real impl would use streaming) first_token_times.push(elapsed.as_millis() as f64 / output.usage.completion_tokens as f64); } let tokens_per_second = (total_tokens as f64 / total_time_ms as f64) * 1000.0; let avg_ttft = first_token_times.iter().sum::<f64>() / first_token_times.len() as f64; let memory_used = backend.resource_usage().memory_mb; let scores = BenchmarkScores { tokens_per_second, time_to_first_token_ms: avg_ttft, memory_efficiency: total_tokens as f64 / memory_used.max(1) as f64, composite: self.calculate_composite(tokens_per_second, avg_ttft), }; let result = BenchmarkResult { timestamp: Utc::now(), backend: backend.name().to_string(), model: "benchmark-model".to_string(), scores, hardware: HardwareInfo::detect()?, }; // Save results self.save_result(&result)?; Ok(result) } fn calculate_composite(&self, tps: f64, ttft: f64) -> f64 { // Weighted: 70% throughput, 30% latency let tps_score = (tps / 50.0).min(1.0); // Normalize to ~50 tok/s baseline let ttft_score = (100.0 / ttft).min(1.0); // Lower is better tps_score * 0.7 + ttft_score * 0.3 } } First-Run Experience (Task 3.8): // src/first_run.rs pub async fn check_first_run(config: &Config) -> Result<()> { let marker_path = config.data_dir.join(".initialized"); if marker_path.exists() { return Ok(()); } tracing::info!("First run detected, starting setup..."); // 1. Create data directories fs::create_dir_all(&config.data_dir)?; fs::create_dir_all(config.data_dir.join("models"))?; fs::create_dir_all(config.data_dir.join("logs"))?; fs::create_dir_all(config.data_dir.join("cache"))?; // 2. Generate worker ID let worker_id = Uuid::new_v4().to_string(); let id_path = config.data_dir.join("worker_id"); fs::write(&id_path, &worker_id)?; tracing::info!("Generated worker ID: {}", worker_id); // 3. Download benchmark model (small ~100MB) let benchmark_model_url = "https://models.ai4all.network/benchmark/tinyllama-1b.gguf"; let model_path = config.data_dir.join("models/benchmark.gguf"); tracing::info!("Downloading benchmark model..."); download_with_progress(benchmark_model_url, &model_path).await?; // 4. Run benchmark tracing::info!("Running initial benchmark (this may take a few minutes)..."); let backend = CpuBackend::new(Default::default())?; backend.load_model(&model_path).await?; let benchmark = BenchmarkSuite::new(&config.data_dir); let result = benchmark.run(&backend).await?; tracing::info!( "Benchmark complete: {:.1} tokens/sec, composite score: {:.2}", result.scores.tokens_per_second, result.scores.composite ); // 5. Write marker file fs::write(&marker_path, Utc::now().to_rfc3339())?; Ok(()) } Directory Structure After Sprint 3: ai4all-worker/ ├── src/ │ ├── main.rs │ ├── cli.rs │ ├── config.rs │ ├── logging.rs │ ├── error.rs │ ├── first_run.rs # First-run setup │ ├── types/ │ │ ├── mod.rs │ │ ├── task.rs │ │ └── model.rs │ ├── backend/ │ │ ├── mod.rs │ │ ├── cpu.rs │ │ └── registry.rs │ ├── protocol/ │ │ ├── mod.rs │ │ ├── messages.rs # Protocol message types │ │ └── connection.rs # WebSocket connection │ └── benchmark/ │ ├── mod.rs # Benchmark suite │ └── hardware.rs # Hardware detection ├── fixtures/ │ └── long_prompt.txt # Benchmark fixture └── tests/ ├── protocol_tests.rs ├── benchmark_tests.rs └── integration/ └── full_flow_test.rs Acceptance Criteria: • Worker connects to mock coordinator via WebSocket • Reconnection with exponential backoff works • Worker registers with capabilities • Task assignment → execution → result submission works • First-run downloads benchmark model and runs benchmark • Benchmark scores saved to local storage • Integration test passes with mock coordinator